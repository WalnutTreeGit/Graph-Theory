{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK4i1Z_2yNTR"
      },
      "outputs": [],
      "source": [
        "!unzip fb100.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z85i3Uhy_qA_",
        "outputId": "aa39e91d-1820-4714-e651-92740b5a2b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing Carnegie49.gml...\n",
            "\n",
            "Evaluating dorm recovery...\n",
            "\n",
            "Evaluating major_index recovery...\n",
            "\n",
            "Evaluating gender recovery...\n",
            "\n",
            "Results Summary:\n",
            "                 Carnegie49.gml\n",
            "dorm_0.1                  0.567\n",
            "dorm_0.2                  0.498\n",
            "dorm_0.3                  0.429\n",
            "major_index_0.1           0.431\n",
            "major_index_0.2           0.336\n",
            "major_index_0.3           0.361\n",
            "gender_0.1                0.582\n",
            "gender_0.2                0.597\n",
            "gender_0.3                0.527\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.sparse import diags\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def label_propagation(G, labels, max_iter=1000, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Implements label propagation algorithm for recovering missing node attributes\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    G : networkx.Graph\n",
        "        The input graph\n",
        "    labels : dict\n",
        "        Dictionary of node:label pairs for known labels\n",
        "    max_iter : int\n",
        "        Maximum number of iterations\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Predicted labels for all nodes\n",
        "    \"\"\"\n",
        "    node_to_idx = {node: idx for idx, node in enumerate(G.nodes())}\n",
        "    idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
        "\n",
        "    A = nx.adjacency_matrix(G)\n",
        "    row_sum = np.array(A.sum(axis=1)).flatten()\n",
        "    row_sum[row_sum == 0] = 1  # Avoid division by zero\n",
        "    Dinv = diags(1.0 / row_sum)\n",
        "    P = Dinv @ A\n",
        "\n",
        "    n_nodes = len(G.nodes)\n",
        "    unique_labels = sorted(set(labels.values()))\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    Y = np.zeros((n_nodes, len(unique_labels)))\n",
        "\n",
        "    for node, label in labels.items():\n",
        "        if label is not None:\n",
        "            Y[node_to_idx[node], label_to_index[label]] = 1\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        Y_prev = Y.copy()\n",
        "        Y = P.dot(Y)\n",
        "\n",
        "        for node in labels:\n",
        "            if labels[node] is not None:\n",
        "                Y[node_to_idx[node], :] = Y_prev[node_to_idx[node], :]\n",
        "\n",
        "        if np.linalg.norm(Y - Y_prev) < tol:\n",
        "            break\n",
        "\n",
        "    index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "    predicted_labels = {}\n",
        "    for idx in range(n_nodes):\n",
        "        node = idx_to_node[idx]\n",
        "        if Y[idx].sum() > 0:\n",
        "            predicted_labels[node] = index_to_label[np.argmax(Y[idx, :])]\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "def randomly_remove_attributes(node_attrs, remove_fraction):\n",
        "    \"\"\"\n",
        "    Randomly remove a fraction of node attributes\n",
        "    \"\"\"\n",
        "    known_labels = {node: attr for node, attr in node_attrs.items() if attr is not None}\n",
        "    total_to_remove = int(len(known_labels) * remove_fraction)\n",
        "    removed_nodes = random.sample(list(known_labels.keys()), total_to_remove)\n",
        "\n",
        "    incomplete_attrs = node_attrs.copy()\n",
        "    for node in removed_nodes:\n",
        "        incomplete_attrs[node] = None\n",
        "\n",
        "    # Return both incomplete attributes and remaining known labels\n",
        "    return incomplete_attrs, {node: attr for node, attr in node_attrs.items()\n",
        "                            if node not in removed_nodes and attr is not None}\n",
        "\n",
        "def evaluate_attribute_recovery(G, attribute_name, remove_fractions=[0.1, 0.2, 0.3]):\n",
        "    \"\"\"\n",
        "    Evaluate label propagation for recovering missing attributes\n",
        "    \"\"\"\n",
        "    # Get original attributes\n",
        "    original_attrs = {node: G.nodes[node].get(attribute_name)\n",
        "                     for node in G.nodes\n",
        "                     if G.nodes[node].get(attribute_name) is not None}\n",
        "\n",
        "    results = defaultdict(dict)\n",
        "\n",
        "    for fraction in remove_fractions:\n",
        "        accuracies = []\n",
        "        for trial in range(3):  \n",
        "            incomplete_attrs, known_labels = randomly_remove_attributes(original_attrs, fraction)\n",
        "\n",
        "            predicted_labels = label_propagation(G, known_labels)\n",
        "\n",
        "            missing_nodes = [node for node in incomplete_attrs if incomplete_attrs[node] is None]\n",
        "            true_labels = [original_attrs[node] for node in missing_nodes\n",
        "                          if node in original_attrs and original_attrs[node] is not None]\n",
        "            recovered_labels = [predicted_labels.get(node) for node in missing_nodes\n",
        "                              if node in predicted_labels]\n",
        "\n",
        "            if true_labels and recovered_labels:\n",
        "                accuracy = sum(1 for y, y_pred in zip(true_labels, recovered_labels)\n",
        "                             if y == y_pred) / len(true_labels)\n",
        "                accuracies.append(accuracy)\n",
        "\n",
        "        results[fraction]['accuracy'] = np.mean(accuracies) if accuracies else 0\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    data_path = \"data\"  \n",
        "    networks_to_analyze = [ 'Carnegie49.gml']\n",
        "    attributes = ['dorm', 'major_index', 'gender']\n",
        "    remove_fractions = [0.1, 0.2, 0.3]\n",
        "\n",
        "    all_results = defaultdict(dict)\n",
        "\n",
        "    for network_file in networks_to_analyze:\n",
        "        print(f\"\\nAnalyzing {network_file}...\")\n",
        "        G = nx.read_gml(os.path.join(data_path, network_file))\n",
        "\n",
        "        for attr in attributes:\n",
        "            print(f\"\\nEvaluating {attr} recovery...\")\n",
        "            results = evaluate_attribute_recovery(G, attr, remove_fractions)\n",
        "\n",
        "            for fraction, metrics in results.items():\n",
        "                all_results[network_file][f\"{attr}_{fraction}\"] = metrics['accuracy']\n",
        "\n",
        "    results_df = pd.DataFrame(all_results).round(3)\n",
        "    print(\"\\nResults Summary:\")\n",
        "    print(results_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPdtI8x9xTEw",
        "outputId": "c81cb171-9615-458c-c363-5c6c901e6662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Carnegie49 network...\n",
            "\n",
            "Results for Carnegie49:\n",
            "--------------------------------------------------\n",
            "\n",
            "Attribute: dorm\n",
            "\n",
            "Evaluating dorm with 10.0% removed\n",
            "\n",
            "Evaluating dorm with 20.0% removed\n",
            "\n",
            "Evaluating dorm with 30.0% removed\n",
            "\n",
            "Fraction | Accuracy | MAE\n",
            "------------------------------\n",
            "   10.0% | 0.5852 | 26.0402\n",
            "   20.0% | 0.5566 | 25.9254\n",
            "   30.0% | 0.4527 | 26.7474\n",
            "\n",
            "Attribute: major_index\n",
            "\n",
            "Evaluating major_index with 10.0% removed\n",
            "\n",
            "Evaluating major_index with 20.0% removed\n",
            "\n",
            "Evaluating major_index with 30.0% removed\n",
            "\n",
            "Fraction | Accuracy | MAE\n",
            "------------------------------\n",
            "   10.0% | 0.3791 | 25.0739\n",
            "   20.0% | 0.2195 | 24.5976\n",
            "   30.0% | 0.3126 | 25.2948\n",
            "\n",
            "Attribute: gender\n",
            "\n",
            "Evaluating gender with 10.0% removed\n",
            "\n",
            "Evaluating gender with 20.0% removed\n",
            "\n",
            "Evaluating gender with 30.0% removed\n",
            "\n",
            "Fraction | Accuracy | MAE\n",
            "------------------------------\n",
            "   10.0% | 0.6365 | 0.4098\n",
            "   20.0% | 0.5810 | 0.4408\n",
            "   30.0% | 0.5451 | 0.4234\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.sparse import diags\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "from tqdm import tqdm\n",
        "\n",
        "def label_propagation(G, labels, max_iter=1000, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Implements label propagation algorithm for recovering missing node attributes\n",
        "    \"\"\"\n",
        "    node_to_idx = {node: idx for idx, node in enumerate(G.nodes())}\n",
        "    idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
        "\n",
        "    A = nx.adjacency_matrix(G)\n",
        "    row_sum = np.array(A.sum(axis=1)).flatten()\n",
        "    row_sum[row_sum == 0] = 1\n",
        "\n",
        "    Dinv = diags(1.0 / row_sum)\n",
        "    P = Dinv @ A\n",
        "\n",
        "    n_nodes = len(G.nodes)\n",
        "    unique_labels = sorted(set(labels.values()))\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    Y = np.zeros((n_nodes, len(unique_labels)))\n",
        "\n",
        "    for node, label in labels.items():\n",
        "        if label is not None:\n",
        "            Y[node_to_idx[node], label_to_index[label]] = 1\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        Y_prev = Y.copy()\n",
        "        Y = P.dot(Y)\n",
        "        for node in labels:\n",
        "            if labels[node] is not None:\n",
        "                Y[node_to_idx[node], :] = Y_prev[node_to_idx[node], :]\n",
        "        if np.linalg.norm(Y - Y_prev) < tol:\n",
        "            break\n",
        "\n",
        "    index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "    predicted_labels = {}\n",
        "    for idx in range(n_nodes):\n",
        "        node = idx_to_node[idx]\n",
        "        if Y[idx].sum() > 0:\n",
        "            predicted_labels[node] = index_to_label[np.argmax(Y[idx, :])]\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "def randomly_remove_attributes(node_attrs, remove_fraction):\n",
        "    \"\"\"\n",
        "    Randomly remove a fraction of node attributes\n",
        "    \"\"\"\n",
        "    known_labels = {node: attr for node, attr in node_attrs.items() if attr is not None}\n",
        "    total_to_remove = int(len(known_labels) * remove_fraction)\n",
        "    removed_nodes = random.sample(list(known_labels.keys()), total_to_remove)\n",
        "\n",
        "    incomplete_attrs = node_attrs.copy()\n",
        "    for node in removed_nodes:\n",
        "        incomplete_attrs[node] = None\n",
        "\n",
        "    return incomplete_attrs, {node: attr for node, attr in node_attrs.items()\n",
        "                            if node not in removed_nodes and attr is not None}\n",
        "\n",
        "def evaluate_label_propagation(G, attribute_name, remove_fractions=[0.1, 0.2, 0.3]):\n",
        "    \"\"\"\n",
        "    Evaluate label propagation for attribute recovery with multiple metrics\n",
        "    \"\"\"\n",
        "    original_attrs = {node: G.nodes[node].get(attribute_name)\n",
        "                     for node in G.nodes\n",
        "                     if G.nodes[node].get(attribute_name) is not None}\n",
        "\n",
        "    results = {}\n",
        "    for fraction in remove_fractions:\n",
        "        print(f\"\\nEvaluating {attribute_name} with {fraction*100}% removed\")\n",
        "\n",
        "        accuracies = []\n",
        "        maes = []\n",
        "        for trial in range(3):\n",
        "            incomplete_attrs, known_labels = randomly_remove_attributes(original_attrs, fraction)\n",
        "\n",
        "            predicted_labels = label_propagation(G, known_labels)\n",
        "\n",
        "            missing_nodes = [node for node in incomplete_attrs if incomplete_attrs[node] is None]\n",
        "            true_labels = [original_attrs[node] for node in missing_nodes\n",
        "                         if node in original_attrs and original_attrs[node] is not None]\n",
        "            recovered_labels = [predicted_labels.get(node) for node in missing_nodes\n",
        "                             if node in predicted_labels]\n",
        "\n",
        "            if true_labels and recovered_labels:\n",
        "                accuracy = sum(1 for y, y_pred in zip(true_labels, recovered_labels)\n",
        "                             if y == y_pred) / len(true_labels)\n",
        "                accuracies.append(accuracy)\n",
        "\n",
        "                try:\n",
        "                    mae = mean_absolute_error([float(y) for y in true_labels],\n",
        "                                            [float(y_pred) for y_pred in recovered_labels])\n",
        "                    maes.append(mae)\n",
        "                except (ValueError, TypeError):\n",
        "                    maes.append(None)\n",
        "\n",
        "        avg_accuracy = np.mean(accuracies) if accuracies else 0\n",
        "        avg_mae = np.mean([mae for mae in maes if mae is not None]) if maes else None\n",
        "\n",
        "        results[fraction] = {\n",
        "            'accuracy': avg_accuracy,\n",
        "            'mae': avg_mae\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    print(\"Loading Carnegie49 network...\")\n",
        "    G = nx.read_gml(\"data/Carnegie49.gml\")\n",
        "\n",
        "    attributes = ['dorm', 'major_index', 'gender']\n",
        "    remove_fractions = [0.1, 0.2, 0.3]\n",
        "\n",
        "    print(\"\\nResults for Carnegie49:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for attr in attributes:\n",
        "        print(f\"\\nAttribute: {attr}\")\n",
        "        results = evaluate_label_propagation(G, attr, remove_fractions)\n",
        "\n",
        "        print(\"\\nFraction | Accuracy | MAE\")\n",
        "        print(\"-\" * 30)\n",
        "        for fraction, metrics in results.items():\n",
        "            mae_str = f\"{metrics['mae']:.4f}\" if metrics['mae'] is not None else \"N/A\"\n",
        "            print(f\"{fraction*100:>7.1f}% | {metrics['accuracy']:.4f} | {mae_str}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTX7TEmF_top"
      },
      "source": [
        "# Question 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ny-qbCFHFaMG",
        "outputId": "1844d95a-fbd0-41c7-d979-c088f2738f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing ./data/American75.gml...\n",
            "Gender Homophily: 0.499\n",
            "Year Homophily: 0.469\n",
            "Gender Assortativity: 0.026\n",
            "Year Assortativity: 0.352\n",
            "\n",
            "Analyzing ./data/Cornell5.gml...\n",
            "Gender Homophily: 0.479\n",
            "Year Homophily: 0.491\n",
            "Gender Assortativity: 0.072\n",
            "Year Assortativity: 0.394\n",
            "\n",
            "Analyzing ./data/MU78.gml...\n",
            "Gender Homophily: 0.529\n",
            "Year Homophily: 0.523\n",
            "Gender Assortativity: 0.102\n",
            "Year Assortativity: 0.417\n",
            "\n",
            "Analyzing ./data/Rice31.gml...\n",
            "Gender Homophily: 0.480\n",
            "Year Homophily: 0.398\n",
            "Gender Assortativity: 0.027\n",
            "Year Assortativity: 0.276\n",
            "\n",
            "Analyzing ./data/UC61.gml...\n",
            "Gender Homophily: 0.454\n",
            "Year Homophily: 0.419\n",
            "Gender Assortativity: 0.004\n",
            "Year Assortativity: 0.290\n",
            "\n",
            "Analyzing ./data/USFCA72.gml...\n",
            "Gender Homophily: 0.522\n",
            "Year Homophily: 0.491\n",
            "Gender Assortativity: 0.022\n",
            "Year Assortativity: 0.364\n",
            "\n",
            "Analyzing ./data/Amherst41.gml...\n",
            "Gender Homophily: 0.465\n",
            "Year Homophily: 0.513\n",
            "Gender Assortativity: 0.047\n",
            "Year Assortativity: 0.409\n",
            "\n",
            "Analyzing ./data/Dartmouth6.gml...\n",
            "Gender Homophily: 0.468\n",
            "Year Homophily: 0.513\n",
            "Gender Assortativity: 0.077\n",
            "Year Assortativity: 0.426\n",
            "\n",
            "Analyzing ./data/Maine59.gml...\n",
            "Gender Homophily: 0.456\n",
            "Year Homophily: 0.332\n",
            "Gender Assortativity: -0.003\n",
            "Year Assortativity: 0.184\n",
            "\n",
            "Analyzing ./data/Rochester38.gml...\n",
            "Gender Homophily: 0.495\n",
            "Year Homophily: 0.496\n",
            "Gender Assortativity: 0.065\n",
            "Year Assortativity: 0.383\n",
            "\n",
            "Analyzing ./data/UC64.gml...\n",
            "Gender Homophily: 0.454\n",
            "Year Homophily: 0.430\n",
            "Gender Assortativity: -0.024\n",
            "Year Assortativity: 0.266\n",
            "\n",
            "Analyzing ./data/UVA16.gml...\n",
            "Gender Homophily: 0.501\n",
            "Year Homophily: 0.501\n",
            "Gender Assortativity: 0.080\n",
            "Year Assortativity: 0.400\n",
            "\n",
            "Analyzing ./data/Auburn71.gml...\n",
            "Gender Homophily: 0.520\n",
            "Year Homophily: 0.320\n",
            "Gender Assortativity: 0.079\n",
            "Year Assortativity: 0.188\n",
            "\n",
            "Analyzing ./data/Duke14.gml...\n",
            "Gender Homophily: 0.497\n",
            "Year Homophily: 0.547\n",
            "Gender Assortativity: 0.084\n",
            "Year Assortativity: 0.454\n",
            "\n",
            "Analyzing ./data/Maryland58.gml...\n",
            "Gender Homophily: 0.487\n",
            "Year Homophily: 0.466\n",
            "Gender Assortativity: 0.048\n",
            "Year Assortativity: 0.352\n",
            "\n",
            "Analyzing ./data/Rutgers89.gml...\n",
            "Gender Homophily: 0.475\n",
            "Year Homophily: 0.438\n",
            "Gender Assortativity: 0.027\n",
            "Year Assortativity: 0.317\n",
            "\n",
            "Analyzing ./data/UCF52.gml...\n",
            "Gender Homophily: 0.503\n",
            "Year Homophily: 0.350\n",
            "Gender Assortativity: 0.027\n",
            "Year Assortativity: 0.212\n",
            "\n",
            "Analyzing ./data/Vanderbilt48.gml...\n",
            "Gender Homophily: 0.517\n",
            "Year Homophily: 0.518\n",
            "Gender Assortativity: 0.125\n",
            "Year Assortativity: 0.417\n",
            "\n",
            "Analyzing ./data/BC17.gml...\n",
            "Gender Homophily: 0.461\n",
            "Year Homophily: 0.654\n",
            "Gender Assortativity: 0.014\n",
            "Year Assortativity: 0.583\n",
            "\n",
            "Analyzing ./data/Emory27.gml...\n",
            "Gender Homophily: 0.510\n",
            "Year Homophily: 0.517\n",
            "Gender Assortativity: 0.077\n",
            "Year Assortativity: 0.415\n",
            "\n",
            "Analyzing ./data/Mich67.gml...\n",
            "Gender Homophily: 0.528\n",
            "Year Homophily: 0.301\n",
            "Gender Assortativity: 0.053\n",
            "Year Assortativity: 0.162\n",
            "\n",
            "Analyzing ./data/Santa74.gml...\n",
            "Gender Homophily: 0.489\n",
            "Year Homophily: 0.519\n",
            "Gender Assortativity: 0.030\n",
            "Year Assortativity: 0.398\n",
            "\n",
            "Analyzing ./data/UCLA26.gml...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9123df8ae0d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_multiple_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gender Homophily bigger:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_homophily_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out of:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_homophily_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0myear_homophily_counter\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9123df8ae0d2>\u001b[0m in \u001b[0;36manalyze_multiple_networks\u001b[0;34m(graph_files)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgraph_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nAnalyzing {graph_file}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHomophilyAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9123df8ae0d2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph_file)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"\"\"Initialize with a GML graph file from FB100 dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_edge_homophily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_read_gml_1\u001b[0;34m(path, label, destringizer, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph_backend_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgraph_backend_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_backend_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m                 elif self._can_convert(\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_backend_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m_call_with_backend\u001b[0;34m(self, backend_name, args, kwargs, extra_message)\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;34m\"\"\"Call this dispatchable function with a backend without converting inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"networkx\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         _logger.debug(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mread_gml\u001b[0;34m(path, label, destringizer)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_gml_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestringizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_gml_lines\u001b[0;34m(lines, label, destringizer)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0mdirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"directed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# EOF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0munexpected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EOF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_kv\u001b[0;34m(curr_token)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mcurr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_START\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# Allow for string convertible id and label values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_dict\u001b[0;34m(curr_token)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mcurr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_START\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'['\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# dict contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;31m# dict end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mcurr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_END\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"']'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_kv\u001b[0;34m(curr_token)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mcurr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_START\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# Allow for string convertible id and label values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mparse_dict\u001b[0;34m(curr_token)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# dict end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mcurr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_END\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"']'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(curr_token, category, expected)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0munexpected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/gml.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class HomophilyAnalyzer:\n",
        "    def __init__(self, graph_file):\n",
        "        \"\"\"Initialize with a GML graph file from FB100 dataset\"\"\"\n",
        "        self.G = nx.read_gml(graph_file)\n",
        "\n",
        "    def calculate_edge_homophily(self):\n",
        "        \"\"\"Calculate proportion of edges between same gender/year nodes\"\"\"\n",
        "        total_edges = self.G.number_of_edges()\n",
        "        same_gender_edges = 0\n",
        "        same_year_edges = 0\n",
        "\n",
        "        for edge in self.G.edges():\n",
        "            node1, node2 = edge\n",
        "            if self.G.nodes[node1]['gender'] == self.G.nodes[node2]['gender']:\n",
        "                same_gender_edges += 1\n",
        "            if self.G.nodes[node1]['year'] == self.G.nodes[node2]['year']:\n",
        "                same_year_edges += 1\n",
        "\n",
        "        return {\n",
        "            'gender_homophily': same_gender_edges / total_edges,\n",
        "            'year_homophily': same_year_edges / total_edges\n",
        "        }\n",
        "\n",
        "    def calculate_mixing_matrices(self):\n",
        "        \"\"\"Calculate mixing matrices for gender and year\"\"\"\n",
        "        gender_mixing = defaultdict(lambda: defaultdict(int))\n",
        "        year_mixing = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for edge in self.G.edges():\n",
        "            node1, node2 = edge\n",
        "            gender1 = self.G.nodes[node1]['gender']\n",
        "            gender2 = self.G.nodes[node2]['gender']\n",
        "            year1 = self.G.nodes[node1]['year']\n",
        "            year2 = self.G.nodes[node2]['year']\n",
        "\n",
        "            gender_mixing[gender1][gender2] += 1\n",
        "            year_mixing[year1][year2] += 1\n",
        "\n",
        "        return gender_mixing, year_mixing\n",
        "\n",
        "    def calculate_attribute_assortativity(self):\n",
        "        \"\"\"Calculate assortativity coefficients for gender and year\"\"\"\n",
        "        gender_assortativity = nx.attribute_assortativity_coefficient(self.G, 'gender')\n",
        "        year_assortativity = nx.attribute_assortativity_coefficient(self.G, 'year')\n",
        "        return gender_assortativity, year_assortativity\n",
        "\n",
        "    def plot_comparison(self, gender_assort, year_assort, gender_homo, year_homo):\n",
        "        \"\"\"Plot comparison of gender vs year influence\"\"\"\n",
        "        labels = ['Assortativity', 'Edge Homophily']\n",
        "        gender_scores = [gender_assort, gender_homo]\n",
        "        year_scores = [year_assort, year_homo]\n",
        "\n",
        "        x = np.arange(len(labels))\n",
        "        width = 0.35\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        rects1 = ax.bar(x - width/2, gender_scores, width, label='Gender')\n",
        "        rects2 = ax.bar(x + width/2, year_scores, width, label='Year')\n",
        "\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title('Gender vs Year Influence on Network Formation')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def analyze_multiple_networks(graph_files):\n",
        "    \"\"\"Analyze multiple networks and compare results\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    global gender_homophily_counter, year_homophily_counter, gender_assort_counter, year_assort_counter\n",
        "    gender_homophily_counter = 0\n",
        "    year_homophily_counter = 0\n",
        "    gender_assort_counter = 0\n",
        "    year_assort_counter = 0\n",
        "\n",
        "\n",
        "    for graph_file in graph_files:\n",
        "        print(f\"\\nAnalyzing {graph_file}...\")\n",
        "        analyzer = HomophilyAnalyzer(graph_file)\n",
        "\n",
        "        homophily = analyzer.calculate_edge_homophily()\n",
        "        gender_assort, year_assort = analyzer.calculate_attribute_assortativity()\n",
        "\n",
        "        results[graph_file] = {\n",
        "            'gender_homophily': homophily['gender_homophily'],\n",
        "            'year_homophily': homophily['year_homophily'],\n",
        "            'gender_assortativity': gender_assort,\n",
        "            'year_assortativity': year_assort\n",
        "        }\n",
        "\n",
        "        # Plot comparison\n",
        "        ''' analyzer.plot_comparison(\n",
        "            gender_assort,\n",
        "            year_assort,\n",
        "            homophily['gender_homophily'],\n",
        "            homophily['year_homophily']\n",
        "        ) '''\n",
        "\n",
        "        print(f\"Gender Homophily: {homophily['gender_homophily']:.3f}\")\n",
        "        print(f\"Year Homophily: {homophily['year_homophily']:.3f}\")\n",
        "        print(f\"Gender Assortativity: {gender_assort:.3f}\")\n",
        "        print(f\"Year Assortativity: {year_assort:.3f}\")\n",
        "\n",
        "\n",
        "        if homophily['gender_homophily']> homophily['year_homophily']:\n",
        "          gender_homophily_counter +=1\n",
        "        else:\n",
        "          year_homophily_counter +=1\n",
        "\n",
        "        if gender_assort > year_assort:\n",
        "          gender_assort_counter +=1\n",
        "        else:\n",
        "          year_assort_counter +=1\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "graph_files = [\n",
        "    './data/American75.gml',\n",
        "    './data/Cornell5.gml',\n",
        "    './data/MU78.gml',\n",
        "    './data/Rice31.gml',\n",
        "    './data/UC61.gml',\n",
        "    './data/USFCA72.gml',\n",
        "    './data/Amherst41.gml',\n",
        "    './data/Dartmouth6.gml',\n",
        "    './data/Maine59.gml',\n",
        "    './data/Rochester38.gml',\n",
        "    './data/UC64.gml',\n",
        "    './data/UVA16.gml',\n",
        "    './data/Auburn71.gml',\n",
        "    './data/Duke14.gml',\n",
        "    './data/Maryland58.gml',\n",
        "    './data/Rutgers89.gml',\n",
        "    './data/UCF52.gml',\n",
        "    './data/Vanderbilt48.gml',\n",
        "    './data/BC17.gml',\n",
        "    './data/Emory27.gml',\n",
        "    './data/Mich67.gml',\n",
        "    './data/Santa74.gml',\n",
        "    './data/UCLA26.gml',\n",
        "    './data/Vassar85.gml',\n",
        "    './data/BU10.gml',\n",
        "    './data/FSU53.gml',\n",
        "    './data/Michigan23.gml',\n",
        "    './data/Simmons81.gml',\n",
        "    './data/UCSB37.gml',\n",
        "    './data/Vermont70.gml',\n",
        "    './data/Baylor93.gml',\n",
        "    './data/GWU54.gml',\n",
        "    './data/Middlebury45.gml',\n",
        "    './data/Smith60.gml',\n",
        "    './data/UCSC68.gml',\n",
        "    './data/Villanova62.gml',\n",
        "    './data/Berkeley13.gml',\n",
        "    './data/Georgetown15.gml',\n",
        "    './data/Mississippi66.gml',\n",
        "    './data/Stanford3.gml',\n",
        "    './data/UCSD34.gml',\n",
        "    './data/Virginia63.gml',\n",
        "    './data/Bingham82.gml',\n",
        "    './data/Hamilton46.gml',\n",
        "    './data/NYU9.gml',\n",
        "    './data/Swarthmore42.gml',\n",
        "    './data/UChicago30.gml',\n",
        "    './data/Wake73.gml',\n",
        "    './data/Bowdoin47.gml',\n",
        "    './data/Harvard1.gml',\n",
        "    './data/Northeastern19.gml',\n",
        "    './data/Syracuse56.gml',\n",
        "    './data/UConn91.gml',\n",
        "    './data/WashU32.gml',\n",
        "    './data/Brandeis99.gml',\n",
        "    './data/Haverford76.gml',\n",
        "    './data/Northwestern25.gml',\n",
        "    './data/Temple83.gml',\n",
        "    './data/UF21.gml',\n",
        "    './data/Wellesley22.gml',\n",
        "    './data/Brown11.gml',\n",
        "    './data/Howard90.gml',\n",
        "    './data/Notre Dame57.gml',\n",
        "    './data/Tennessee95.gml',\n",
        "    './data/UGA50.gml',\n",
        "    './data/Wesleyan43.gml',\n",
        "    './data/Bucknell39.gml',\n",
        "    './data/Indiana69.gml',\n",
        "    './data/Oberlin44.gml',\n",
        "    './data/Texas80.gml',\n",
        "    './data/UIllinois20.gml',\n",
        "    './data/William77.gml',\n",
        "    './data/Cal65.gml',\n",
        "    './data/JMU79.gml',\n",
        "    './data/Oklahoma97.gml',\n",
        "    './data/Texas84.gml',\n",
        "    './data/UMass92.gml',\n",
        "    './data/Williams40.gml',\n",
        "    './data/Caltech36.gml',\n",
        "    './data/Johns Hopkins55.gml',\n",
        "    './data/Penn94.gml',\n",
        "    './data/Trinity100.gml',\n",
        "    './data/UNC28.gml',\n",
        "    './data/Wisconsin87.gml',\n",
        "    './data/Carnegie49.gml',\n",
        "    './data/Lehigh96.gml',\n",
        "    './data/Pepperdine86.gml',\n",
        "    './data/Tufts18.gml',\n",
        "    './data/UPenn7.gml',\n",
        "    './data/Yale4.gml',\n",
        "    './data/Colgate88.gml',\n",
        "    './data/MIT8.gml',\n",
        "    './data/Princeton12.gml',\n",
        "    './data/Tulane29.gml',\n",
        "    './data/USC35.gml',\n",
        "    './data/Columbia2.gml',\n",
        "    './data/MSU24.gml',\n",
        "    './data/Reed98.gml',\n",
        "    './data/UC33.gml',\n",
        "    './data/USF51.gml',\n",
        "]\n",
        "\n",
        "\n",
        "results = analyze_multiple_networks(graph_files)\n",
        "\n",
        "print(\"Gender Homophily bigger:\", gender_homophily_counter, \"out of:\", gender_homophily_counter + year_homophily_counter )\n",
        "print(\"Gender assor bigger:\", gender_assort_counter, \"out of:\", gender_assort_counter + year_assort_counter )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlepCqV-TFLQ",
        "outputId": "789a6320-9a4c-4fca-a717-02e64125486e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gender Homophily bigger: 12 out of: 22\n",
            "Gender assor bigger: 0 out of: 22\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Gender Homophily bigger:\", gender_homophily_counter, \"out of:\", gender_homophily_counter + year_homophily_counter )\n",
        "print(\"Gender assor bigger:\", gender_assort_counter, \"out of:\", gender_assort_counter + year_assort_counter )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
